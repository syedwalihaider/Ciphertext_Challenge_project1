{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Import some important libraris for analysis and Visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the training data set. Ciphertext column consist encoded text, Id, and target which consist of 20 different encoding techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ciphertext</th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W)(7\u001ayT7h8;Hv\\nlTcH;hHhNW)%HhMNPcHNG_Cy^PvMBMy...</td>\n",
       "      <td>ID_48096b7a9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W)(7\u001ayqv(H3cl-iNHv\u001e",
       "cNMrcNv3y^](H\\ny\\tNy\u0003c/syPc...</td>\n",
       "      <td>ID_a2d6e55f4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W)(7\u001ayqM()qMl7;HTvM)N\\n()8N%hNc8syPcu4Mhv\u001ayO(H...</td>\n",
       "      <td>ID_9dde342f6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W)(7\u001ayH=j0j?&amp;Il\u001e",
       "MHT(HNhhN33cNMrcy^\\%7MTyX(cq1%...</td>\n",
       "      <td>ID_b637c2642</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W)(7\u001ay8()MHM8lH7v;Nh(7y^q%)\\ny8()MHM8/syPcu4Mh...</td>\n",
       "      <td>ID_51b0f15e7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>W)(7\u001ay77%HH;Hql;h(7T;7Nh(7y^C;h\u001e",
       "%M1yC%HH;Hq/sy...</td>\n",
       "      <td>ID_c52813363</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>_)q%H;i%v;(H\u001ayPv%HL()ryp;HM%)y@hhM1M)%v()yGMHv...</td>\n",
       "      <td>ID_bcf3c2d23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>W)(7\u001ayL)%H8lXjI0P+&amp;nNcch y^W)%H8y_UX3\\nM)/syPc...</td>\n",
       "      <td>ID_ad45bfbe4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>W)(7\u001ay7;h\u001e",
       "%M1l4MTvM)N\\t-ONrMy^C;h\u001e",
       "%M1y\\tM)\u001e",
       "%)r...</td>\n",
       "      <td>ID_99ab693a9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>W)(7\u001ay4;7l)%HrN()qy^\\;7y\\t;11(q1\\n/syPcu4Mhv\u001ay...</td>\n",
       "      <td>ID_428cbeff1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5631 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ciphertext            Id  target\n",
       "0     W)(7\u001ayT7h8;Hv\\nlTcH;hHhNW)%HhMNPcHNG_Cy^PvMBMy...  ID_48096b7a9      12\n",
       "1     W)(7\u001ayqv(H3cl-iNHv\n",
       "cNMrcNv3y^](H\\ny\\tNy\u0003c/syPc...  ID_a2d6e55f4       2\n",
       "2     W)(7\u001ayqM()qMl7;HTvM)N\\n()8N%hNc8syPcu4Mhv\u001ayO(H...  ID_9dde342f6      11\n",
       "3     W)(7\u001ayH=j0j?&Il\n",
       "MHT(HNhhN33cNMrcy^\\%7MTyX(cq1%...  ID_b637c2642      16\n",
       "4     W)(7\u001ay8()MHM8lH7v;Nh(7y^q%)\\ny8()MHM8/syPcu4Mh...  ID_51b0f15e7       3\n",
       "...                                                 ...           ...     ...\n",
       "5626  W)(7\u001ay77%HH;Hql;h(7T;7Nh(7y^C;h\n",
       "%M1yC%HH;Hq/sy...  ID_c52813363       8\n",
       "5627  _)q%H;i%v;(H\u001ayPv%HL()ryp;HM%)y@hhM1M)%v()yGMHv...  ID_bcf3c2d23       1\n",
       "5628  W)(7\u001ayL)%H8lXjI0P+&nNcch y^W)%H8y_UX3\\nM)/syPc...  ID_ad45bfbe4       0\n",
       "5629  W)(7\u001ay7;h\n",
       "%M1l4MTvM)N\\t-ONrMy^C;h\n",
       "%M1y\\tM)\n",
       "%)r...  ID_99ab693a9       3\n",
       "5630  W)(7\u001ay4;7l)%HrN()qy^\\;7y\\t;11(q1\\n/syPcu4Mhv\u001ay...  ID_428cbeff1      11\n",
       "\n",
       "[5631 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\ML_project\\ciphertextproject\\train.csv\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is the problem of multiclass classification. First we check wether the dataset is balanced or imbalanced.\n",
    "Since each class consist approx 200 to 300 observation, i considered it is balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    181\n",
       "18    219\n",
       "0     244\n",
       "5     274\n",
       "14    275\n",
       "17    276\n",
       "6     279\n",
       "4     282\n",
       "3     283\n",
       "16    286\n",
       "13    288\n",
       "1     288\n",
       "10    288\n",
       "2     291\n",
       "12    300\n",
       "7     305\n",
       "8     306\n",
       "11    312\n",
       "9     326\n",
       "15    328\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset is balanced.\n",
    "train_data.target.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into x and y. where x is the ciphertext and y is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[\"ciphertext\"]\n",
    "y = train_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W)(7\\x1ayT7h8;Hv\\nlTcH;hHhNW)%HhMNPcHNG_Cy^PvMBMyCh9;Hv\\ny6yPcHG(HHMhvy:GOG/syPcu4Mhv\\x1ay}M\\x1ay\\x03\\x1e%vyr(yOch1M%)yP;vMUTyG((1;Hqy](3M)Tyr(|sy_)q%H;i%v;(H\\x1ayPcHG(HHMhvsyp;HMT\\x1ay0+syX;Tv);ucv;(H\\x1ay3()1rsyOO]m6m(Tv;Hq6\\x1b(Tv\\x1ay\\x1e%)r\\nNL)%HhMNTcHNh(7sy9M\\n3()rT\\x1ayOch1M%)sysy:Hy%)v;h1MyFIk1q=(Er\"klTMkc(;%NhhTrNcvTNQX-N@-\\x1c`yT3%18M)lcvTNQX-N@-y^6Tn\"0\"Ij\"\"6TN3%18M)67%H6&j6/y3);vMT\\x1asy\\x1cysy\\x1cysy\\x1cy:y)M%11\\nyr(HUvy8H(3y3\\x1eM)Myv(y (Tvyv\\x1e;TykcMTv;(HyT(y:yL;qc)Mryv\\x1e%vsy\\x1cyv\\x1e;Tyu(%)ry3(c1ryuMy7(Tvy%  )( );%vMNsy\\x1cy:y3%Ty3(HrM);Hqy%u(cvyv\\x1e(TMy7%TT;BMyh(Hh)MvMyh\\n1;HrM)Tyv\\x1e%vsy\\x1cy%)MyMBM)y )MTMHvy%vyHch1M%)y (M)yT;vMTNy]\\x1eM\\ny1((8y1;8Myh\\n1;HrM)Tsy\\x1cyv\\x1e%vy\\x1e%BMyuMMHy ;Hh\\x1eMry;Hyv\\x1eMy7;rr1MNyX(MTy%H\\nu(r\\ny8H(3y3\\x1e%vyv\\x1eMsy\\x1cy%hvc%1y c) (TMy(Lyv\\x1e(TMyv\\x1e;HqTy%)M|Ny:y\\x1eM%)yv\\x1e%vyv\\x1eM\\nU)Myh%11Mrsy\\x1cyUG((1;Hqy](3M)TUyucvy3\\x1e%vyv\\x1eMy\\x1eMh8yr(yv\\x1eM\\nyh((1|sysy\\x03%vM)NyOch1M%)yTv%v;(HTyr(HUvyqMHM)%vMyM1Mhv);h;v\\nyr;)Mhv1\\nyL)(7yv\\x1eMsy)M%hv()`yv\\x1eM\\nycTMyv\\x1eMy)M%hv()yv(yqMHM)%vMy\\x1eM%vNy]\\x1eMy\\x1eM%vy;Tyv\\x1eMHycTMryv(sy\\x1eM%vy3%vM)y4cTvy%Ty;Hy%yh(HBMHv;(H%1y(;1y()yh(%1yTv%v;(H`y%Hryv\\x1eMsy)MTc1v%HvyTvM%7yr);BMTyv\\x1eMyvc)u;HMTNsysy]\\x1eMyh((1;Hqyv(3M)Ty%)MycTMryv(yh((1yv\\x1eMyTvM%7y%Hry)Mh(HrMHTMy;vy;Hv(y3%vM)syv(yh(Hv;HcMyv\\x1eMyh\\nh1MsysyPvMBMsysy66ysyPvMBMyCh9;Hv\\nsyPcHyC;h)(T\\nTvM7Ty:GOGsy?n0\\x02jyCM\\n1%H`yW)%HhMsyM7%;1\\x1ayT7h8;Hv\\nlL)%HhMNTcHNh(7,yyya:\\x10\\x1ayT7h8;Hv\\ns'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some Vectorization function,GridSearchCV for Hyperparameter tunning, Machine Learning algorithm, from scikit learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the text is continous and there is no spaces between word because space is also encoded to some character, thus i use Tfidf and Countvectorizer with an analyzer as 'char' and taking the ngram_range between 1,6 means combination of maximum 6 character of words present in the documents also max_df is 250, means those ngrams words which have a repitation more than 250 in the documents are dropped from the new feature and same with minimum repitation min_df = 50. Put the lower case is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=False,analyzer='char',ngram_range=(1, 6),max_df=250,min_df=50)\n",
    "count_vec = CountVectorizer(lowercase=False,analyzer='char',ngram_range=(1, 6),max_df=250,min_df=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the text and transform it into vector form, using the function fit and transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = tfidf.fit_transform(x)\n",
    "count_vec_array = count_vec.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_array.shape)\n",
    "print(count_vec_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary of models and list of its hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'naive_bayes':{'model': MultinomialNB(),'params': {'alpha':[1,3,5]}},\n",
    "                'logisticregression':{'model':LogisticRegression(),'params':{'C':[0.1,1,10,20]}},\n",
    "                'svm':{'model':SVC(),'params':{'kernel':['rbf','linear'],'C':[.1,1,5,10]}},\n",
    "                'randomdorest':{'model':RandomForestClassifier(),'params':{'max_depth':[8,15,25,40]}}\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the vector training data into gridSearchCV which will train and check the model accuracy for CV datasets at different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for model_name , models in model_params.items():\n",
    "    clf = GridSearchCV(models['model'],models['params'],scoring='f1_macro',cv=3,n_jobs=-1)\n",
    "    score = clf.fit(tfidf_array,y)\n",
    "    scores.append({'model_names':model_name,'best_score':clf.best_score_,\"best_param\":clf.best_params_})\n",
    "scores_df = pd.DataFrame(scores,columns=['model_names','best_score',\"best_param\"])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = []\n",
    "for model_name , models in model_params.items():\n",
    "    clf1 = GridSearchCV(models['model'],models['params'],scoring='f1_macro',cv=3,n_jobs=-1)\n",
    "    score1 = clf1.fit(count_vec_array,y)\n",
    "    scores1.append({'model_names':model_name,'best_score':clf1.best_score_,\"best_param\":clf1.best_params_})\n",
    "scores1_df = pd.DataFrame(scores1,columns=['model_names','best_score',\"best_param\"])\n",
    "scores1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the best vectorization technique is countvectorizer and logostic regression give maximum f1 score.So i will explore more\n",
    "# on CountVectorizer with LogisticRegression to improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\ML_project\\ciphertextproject\\test.csv\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(lowercase=False,analyzer='char',ngram_range=(4, 6),max_df=500,min_df=10)\n",
    "count_vec_array = count_vec.fit_transform(x)\n",
    "count_vec_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=0.1)\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(logreg,count_vec_array,y,cv=3,scoring='f1_macro',n_jobs=-1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(count_vec_array,y)\n",
    "y_pred = logreg.predict(count_vec_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count_vec = count_vec.transform(test_data[\"ciphertext\"])\n",
    "test_count_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = logreg.predict(test_count_vec)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'trained_model.sav'\n",
    "pickle.dump(logreg,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vec,open('vectorizer.sav','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model in spyder to make a webapp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('trained_model.sav','rb'))\n",
    "loaded_vectorizer = pickle.load(open('vectorizer.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
